{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A Deep Neural Network Model\n",
    "\n",
    "This notebook takes the preprocessed dataset from the previous notebook and develops a DNN model to predict property violations. The preprocessing is repeated here, without the data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn.preprocessing as prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (11,12,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "## Import Data ##\n",
    "df_train = pd.read_csv(\"/Users/tal/Dropbox/Data_Science/Sample ML Project/train.csv\",\n",
    "                       encoding = 'ISO-8859-1')\n",
    "df_test = pd.read_csv(\"/Users/tal/Dropbox/Data_Science/Sample ML Project/test.csv\",\n",
    "                       encoding = 'ISO-8859-1')\n",
    "df_addresses = pd.read_csv(\"/Users/tal/Dropbox/Data_Science/Sample ML Project/addresses.csv\",\n",
    "                       encoding = 'ISO-8859-1')\n",
    "df_latlon = pd.read_csv(\"/Users/tal/Dropbox/Data_Science/Sample ML Project/latlons.csv\",\n",
    "                       encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare initial train and test dataframes ##\n",
    "df_addresses = df_addresses.merge(df_latlon, how = 'outer', on = 'address')\n",
    "df_train = df_train.merge(df_addresses, how = 'inner', on = 'ticket_id')\n",
    "df_train = df_train[~pd.isnull(df_train['compliance'])]\n",
    "df_train = df_train.set_index('ticket_id')\n",
    "\n",
    "df_test = df_test.merge(df_addresses, how = 'inner', on = 'ticket_id')\n",
    "df_test = df_test.set_index('ticket_id')\n",
    "\n",
    "y = df_train['compliance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training and test set for consistent preprocessing\n",
    "df_joint = pd.concat([df_train, df_test], copy = False)\n",
    "\n",
    "# Select features\n",
    "df_joint = df_joint[['agency_name', 'state', 'violation_code', 'disposition', 'fine_amount', 'late_fee', \n",
    "                     'discount_amount', 'lat', 'lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_rare_cat_to_zero(column, min_count = 100):\n",
    "    # This function changes to \"other\" categories with fewer occurrences than a given value.\n",
    "    vc = column.value_counts()\n",
    "    values_to_keep = vc[vc > min_count].index\n",
    "    return column.apply (lambda x: x if x in values_to_keep else \"other\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the number of categorical values\n",
    "categorical_vars = ['agency_name', 'state', 'violation_code', 'disposition']\n",
    "for var in categorical_vars: set_rare_cat_to_zero(df_joint[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the prompt for the final project indicates, there appears to be a small number of incorrect values that are outside \n",
    "# the city limits. Here, I set values that are clearly outside the city limits to the mean.\n",
    "\n",
    "mean_lat = df_joint['lat'].mean()\n",
    "mean_lon = df_joint['lon'].mean()\n",
    "\n",
    "df_joint['lat'] = df_joint['lat'].apply(lambda x: x if (x > 42.23) and (x < 42.451) else mean_lat)  \n",
    "df_joint['lon'] = df_joint['lon'].apply(lambda x: x if (x < -82.88) and (x > -83.3) else mean_lon)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add polynomial features to geographical data\n",
    "poly = prep.PolynomialFeatures(3)\n",
    "lonlat_poly = poly.fit_transform(df_joint[['lat', 'lon']])\n",
    "poly_names = poly.get_feature_names(input_features=['lat', 'lon'])\n",
    "for i in range (3,10):\n",
    "    df_joint[poly_names[i]] = lonlat_poly[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features into dummy variables \n",
    "df_joint_dum = pd.get_dummies(df_joint, drop_first = True, sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "numerical_vars = list(df_joint_dum.columns[0:12])\n",
    "scaler = prep.MinMaxScaler(feature_range = (0, 1))\n",
    "df_joint_dum[numerical_vars] = scaler.fit_transform(df_joint_dum[numerical_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-split dataframe into training and test sets\n",
    "df_train_processed = df_joint_dum.merge(pd.DataFrame(df_train.index), how = 'inner', right_on = 'ticket_id', \n",
    "                                        left_index = True)\n",
    "df_test_processed = df_joint_dum.merge(pd.DataFrame(df_test.index), how = 'inner', right_on = 'ticket_id', \n",
    "                                       left_index = True)\n",
    "df_train_processed = df_train_processed.set_index('ticket_id')\n",
    "df_test_processed = df_test_processed.set_index('ticket_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data to training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train_processed, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure train and validation sets for DNN\n",
    "X_train = X_train.values.T\n",
    "X_val = X_val.values.T\n",
    "Y_train = y_train.values.reshape(1,-1)\n",
    "Y_val = y_val.values.reshape(1,-1)\n",
    "Y_train = np.concatenate((Y_train, 1 - Y_train))\n",
    "Y_val = np.concatenate((Y_val, 1 - Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    This is a utility function from the course Improving Deep Neural Networks: Hyperparameter tuning, \n",
    "    Regularization and Optimization (by deeplearning.ai).\n",
    "    \n",
    "    The function creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = int(X.shape[1])                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((int(Y.shape[0]), m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Network Configuration ###\n",
    "ops.reset_default_graph()  \n",
    "\n",
    "print_cost = True\n",
    "print_freq = 50\n",
    "\n",
    "# Configure hyperparameters\n",
    "NODES_IN_HIDDEN_LAYER_1 = 100\n",
    "NODES_IN_HIDDEN_LAYER_2 = 100\n",
    "LEARNING_RATE = .05\n",
    "NUM_EPOCHS = 200 \n",
    "MINIBATCH_SIZE = 64\n",
    "REGULARIZATION_CONSTANT = 0.0001 \n",
    "\n",
    "tf.set_random_seed(1)                             # to keep consistent results\n",
    "seed = 3                                          # to keep consistent results\n",
    "m = int(X_train.shape[1])                         # m : number of examples in the train set\n",
    "n_x = int(X_train.shape[0])                       # n_x: input size\n",
    "n_y = int(Y_train.shape[0])                       # n_y : output size \n",
    "num_minibatches = int(m/MINIBATCH_SIZE) \n",
    "costs = []  \n",
    "\n",
    "# Create Placeholders \n",
    "X = tf.placeholder(tf.float32, shape = (n_x, None), name = 'X')\n",
    "Y = tf.placeholder(tf.float32, shape = (n_y, None), name = 'Y')\n",
    "\n",
    "# Initialize parameters  \n",
    "W1 = tf.get_variable(\"W1\", [NODES_IN_HIDDEN_LAYER_1, n_x], initializer = tf.contrib.layers.xavier_initializer(seed = 1), regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_CONSTANT))\n",
    "b1 = tf.get_variable(\"b1\", [NODES_IN_HIDDEN_LAYER_1, 1], initializer = tf.zeros_initializer(), regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_CONSTANT))\n",
    "W2 = tf.get_variable(\"W2\", [NODES_IN_HIDDEN_LAYER_2, NODES_IN_HIDDEN_LAYER_1], initializer = tf.contrib.layers.xavier_initializer(seed = 1), regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_CONSTANT))\n",
    "b2 = tf.get_variable(\"b2\", [NODES_IN_HIDDEN_LAYER_2, 1], initializer = tf.zeros_initializer(), regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_CONSTANT))\n",
    "W3 = tf.get_variable(\"W3\", [2, NODES_IN_HIDDEN_LAYER_2], initializer = tf.contrib.layers.xavier_initializer(seed = 1), regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_CONSTANT))\n",
    "b3 = tf.get_variable(\"b3\", [2, 1], initializer = tf.zeros_initializer(), regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_CONSTANT))\n",
    "\n",
    "# Forward propogation\n",
    "Z1 = tf.matmul(W1, tf.cast(X, tf.float32)) + b1                                   \n",
    "A1 = tf.nn.relu(Z1)                                         \n",
    "Z2 = tf.add(tf.matmul(W2, A1), b2)                                        \n",
    "A2 = tf.nn.relu(Z2)                                           \n",
    "Z3 = tf.add(tf.matmul(W3, A2), b3)                                             \n",
    "\n",
    "# Compute costs\n",
    "logits = tf.transpose(Z3)\n",
    "labels = tf.transpose(Y)\n",
    "# tf.get_variable('a', regularizer=tf.contrib.layers.l2_regularizer(REGULARIZATION_CONSTANT))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = labels)) + tf.losses.get_regularization_loss()\n",
    "\n",
    "# Define gradient descent optimizer for backward propogation\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = LEARNING_RATE).minimize(cost)\n",
    "\n",
    "# Initialize all the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.235457  Time: 5.824993\n",
      "Cost after epoch 50: 0.210971  Time: 225.186451\n",
      "Cost after epoch 100: 0.206087  Time: 432.805540\n",
      "Cost after epoch 150: 0.203960  Time: 641.934843\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train AUC is 0.8214090003194859\n",
      "Test AUC is 0.8025508839091186\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initialization\n",
    "    sess.run(init)\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    # Do the training loop\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        epoch_cost = 0.                       # Define a cost related to an epoch\n",
    "        seed = seed + 1\n",
    "        minibatches = random_mini_batches(X_train, Y_train, MINIBATCH_SIZE, seed)\n",
    "\n",
    "        for minibatch in minibatches:\n",
    "\n",
    "            # Select a minibatch\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "            \n",
    "            # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "            _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "  \n",
    "            epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "        # Print the cost every epoch\n",
    "        if print_cost == True and epoch % print_freq == 0:\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost), \" Time: %f\" % (time.time() - start))\n",
    "        if print_cost == True and epoch % 5 == 0:\n",
    "            costs.append(epoch_cost)\n",
    "\n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(LEARNING_RATE))\n",
    "    plt.show()\n",
    "\n",
    "    print (\"Parameters have been trained!\")\n",
    "\n",
    "    prediction = tf.sigmoid(Z3)    \n",
    "    fpr_dnn, tpr_dnn, _ = roc_curve(y_train, prediction.eval({X: X_train, Y: Y_train})[0])\n",
    "    train_auc = auc(fpr_dnn, tpr_dnn)\n",
    "    fpr_dnn, tpr_dnn, _ = roc_curve(y_val, prediction.eval({X: X_val, Y: Y_val})[0])\n",
    "    test_auc = auc(fpr_dnn, tpr_dnn)\n",
    "\n",
    "\n",
    "    print ('Train AUC is', train_auc)    \n",
    "    print ('Test AUC is', test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix - Hyperparameter Tuning\n",
    "### Initial model\n",
    "#### Configuration\n",
    "* NODES_IN_HIDDEN_LAYER_1 = 25\n",
    "* NODES_IN_HIDDEN_LAYER_2 = 12\n",
    "* LEARNING_RATE = 0.0001\n",
    "* NUM_EPOCHS = 1500 \n",
    "* MINIBATCH_SIZE = 32\n",
    "#### Results\n",
    "* Time: over two hour\n",
    "* Test AUC (after 100 epochs): ~.75\n",
    "* Test AUC (1500 epochs): .7886\n",
    "* Cost (1500) epochs: .2108\n",
    "\n",
    "The initial model took over two hours to train and had AUC that was lower than all the other tested machine lerning models. \n",
    "### Tuning the learning rate\n",
    "As a first step, I seek to increase training efficiency so I can experiment and iterate quickly. Therefore, I am starting by optimizing the learning rate. I'm running a short training (100 epochs) on the following model:\n",
    "#### Configuration\n",
    "* NODES_IN_HIDDEN_LAYER_1 = 100\n",
    "* NODES_IN_HIDDEN_LAYER_2 = 100\n",
    "* LEARNING_RATE = 0.0002\n",
    "* NUM_EPOCHS = 100 \n",
    "* MINIBATCH_SIZE = 64\n",
    "#### Results\n",
    "* Time (90): 387 sec\n",
    "* Test AUC (100): .7662\n",
    "* Cost (90 epochs): .2187\n",
    "\n",
    "This model gets an AUC that is not too far from the initial model in a small fraction of the time. I keep running experiments using 50-100 epochs. \n",
    "\n",
    "  Architecture       | Hyperparams       | Results    \n",
    "  -------------      | -------------     | --------------------\n",
    "  HL1:100, HL2:100   | LR:0.0005, MBS:64 | TestAUC(100e):.7745, TrainAUC: .7772, Time(90e):367\n",
    "  HL1:100, HL2:100   | LR:0.005,  MBS:64 | TestAUC(50e):.7935, TrainAUC:7935, Time(40e):164    |\n",
    "  HL1:100, HL2:100   | **LR:0.05**,   MBS:64 | **TestAUC(50e):.8018**, TrainAUC:.8154, Time(40e):168    |\n",
    "  HL1:100, HL2:100   | LR:0.1,    MBS:64 | TestAUC(50e):.7967, TrainAUC:.8091, Time(40e):178    |\n",
    "  HL1:100, HL2:100   | LR:0.5,    MBS:64 | TestAUC(50e):.7936, TrainAUC:..8154, Time(40e):173    |\n",
    "**HL#**: number of neurons in hidden layer #.  **LR**: learning rate.  **(#e)**: number of epochs after which the metric is measured.\n",
    "  \n",
    "The best learning rate is 0.05\n",
    "### Tuning the minibatch size\n",
    " Architecture       | Hyperparams       | Results    \n",
    "  -------------      | -------------     | --------------------\n",
    "  HL1:100, HL2:100   | LR:0.05,  MBS:32 | TestAUC(50e):.8020, TrainAUC:.8143, Time(40e):258    |\n",
    "  HL1:100, HL2:100   | LR:0.05,   **MBS:64** | TestAUC(50e):.8018, TrainAUC:.8154, Time(40e):168    |\n",
    "  HL1:100, HL2:100   | LR:0.05,    MBS:128 | TestAUC(50e):.7983, TrainAUC:.8069, Time(40e):134    |\n",
    "Considering both Test AUC and training time, the optimal Minibatch Size is 64. \n",
    "### Tuning the network architecture\n",
    " Architecture       | Hyperparams       | Results    \n",
    "  -------------      | -------------    | --------------------\n",
    "  HL1:100, HL2:100   | LR:0.05, MBS:64  | TestAUC(50e):.8018, TrainAUC:.8154, Time(40e):168    |\n",
    "  HL1:500, HL2:500   | LR:0.05, MBS:64  | TestAUC(50e):.8031, TrainAUC:.8171, Time(40e):438    |\n",
    "  HL1:20, HL2:20   | LR:0.05, MBS:64  | TestAUC(100e):.7857, TrainAUC:.8008, Time(90e):293    |\n",
    "  HL1:50, HL2:50   | LR:0.05, MBS:64  | TestAUC(100e):.8031, TrainAUC:.8189, Time(90e):324    |\n",
    "  HL1:150, HL2:72   | LR:0.05, MBS:64  | TestAUC(50e):.8018, TrainAUC:.8129, Time(40e):176    |\n",
    "  HL1:100, HL2:100, HL3:100   | LR:0.05, MBS:64  | TestAUC(50e):.8008, TrainAUC:.8069, Time(40e):134    |\n",
    "I could experiment more here (especially using more epochs and regularization), but a preliminary testing shows that the model with two layers of 100 each is performing well, in terms of tradeoff between AUC and training time.\n",
    "### Tuning the regularization constant\n",
    "I ran the model with the chosen hyperparameters with 1000 epochs, and the result indicated that it overfit: TestAUC(1000e):.8530, TrainAUC:(1000e).7533. Therefore, I added l2 regularization.\n",
    "\n",
    "Reg Constant       | Results    | Comments\n",
    "  -------------      | -------------    | --------------------\n",
    "  Reg Constant: 0   |  TestAUC(50e):.8018, TrainAUC:(50e).8154, TestAUC(1000e):.7533, TrainAUC:(1000e).8530   | Benchmark with no regularization\n",
    "Reg Constant: 0.001 | TrainAUC(200e):.7949, Test AUC(200e):.7900 | This model seems to underfit\n",
    "Reg Constant: 0.0001 | TestAUC(100e):.8021, TrainAUC:(100e).8155, TestAUC(200e):.8025, TrainAUC:(200e).8214| TrainAUC improves, but not TestAUC: overfitting \n",
    "Reg Constant: 0.0002 | TrainAUC(200e):.8151, Test AUC(200e):.8005 | After 200 epochs, less overfitting than 0.0001.\n",
    "Reg Constant: 0.0002 | TrainAUC(1000e):.8180, Test AUC(1000e):.7972 | See below\n",
    "\n",
    "The regularization (0.0002) with 1,000 epochs yields lesser results than the unregularized model with 100 epochs. \n",
    "\n",
    "Overall, no DNN had a Test AUC that exceeded 0.8031. This is better than the Linear Regression model, but not as good as the Ranadom Forest and the KNN. It is possible the further tuning could improve this model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
